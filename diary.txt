    Week 1: I spent week 1 trying to understand how to use Hadoop and familiarising myself with its syntax. I borrowed a book from the library (Hadoop: the definitive guide) and watched a couple of YouTube videos in order to gain an understanding of the basics of Hadoop. Thereafter, to practise my knowledge, I tried unsuccessfully to setup Hadoop on my local system for which I suspect that my environment variables were not setup the correct way. Therefore, I started using noMachine in order to familiarise myself with its usage since it easily allows you to connect to the big data system at RHUL. Moreover, I noticed that my git repository has not been created so I emailed the CIM helpdesk team to sort out the problem.

    Week 2: I spent week 2 working on problem 1. During this week, all my efforts were dedicated to writing a java file such that it takes a text file as an input and outputs the number of occurrences for each word contained in that text file. Although I did not specify that a text file was going to be the input, I still continued with the idea since I received approval from my supervisor. The task itself was not difficult at all as I have tackled similiar tasks in the past. 

    Week 3: During the start of week 3, I modified the code for problem 1 such that it now takes a few HTML pages (poetry related webpages) as input and then outputs the occurence of each word in the poem. The task proved to be a bit more difficult than previously thought since I had to perform the counting of each word for only a section of the webpage (the poem itself). To tackle this problem, I used regex so that the algorithm is only performed when it encounters the div with id="post_description" and it stops after its closure. Moreover, I used regex in order to omit any words starting with "href" and any HTML tags from the word count.